{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3: Regression with Gaussian Processes\n",
    "\n",
    "#### Author: Antonio Miranda\n",
    "------------------------------------------------------\n",
    "*Machine Learning, Master in Big Data Analytics, 2018-2019*\n",
    "\n",
    "*Pablo M. Olmos olmos@tsc.uc3m.es*\n",
    "\n",
    "------------------------------------------------------\n",
    "\n",
    "The aim of this homework is to solve a real data problem using the Gaussian Process implementation of GPy. The documentation of GPy is avaialable from the [SheffieldML github page](https://github.com/SheffieldML/GPy) or from [this page](http://gpy.readthedocs.org/en/latest/). \n",
    "\n",
    "The problem is the prediction of both the heating load (HL) and cooling load (CL) of residential buildings. We consider eight input variables for each building: relative compactness, surface area, wall area, roof area, overall height, orientation, glazing area, glazing area distribution.\n",
    "\n",
    "In this [paper](https://www.sciencedirect.com/science/article/pii/S037877881200151X) you can find a detailed description of the problem and a solution based on linear regression [(iteratively reweighted least squares (IRLS) algorithm)](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=10&ved=2ahUKEwjZuoLY2OjgAhUs3uAKHUZ7BVcQFjAJegQIAhAC&url=https%3A%2F%2Fpdfs.semanticscholar.org%2F9b92%2F18e7233f4d0b491e1582c893c9a099470a73.pdf&usg=AOvVaw3YDwqZh1xyF626VqfnCM2k) and random forests. Using GPs, our goal is not only estimate accurately both HL and CL, but also get a measure of uncertainty in our predictions.\n",
    "\n",
    "The data set can be downloaded from the [UCI repository](https://archive.ics.uci.edu/ml/datasets/Energy+efficiency#)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading and preparing the data\n",
    "\n",
    "* Download the dataset\n",
    "* Divide at random the dataset into train (80%) and test (20%) datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import GPy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Download dataset\n",
    "data = pd.read_excel('ENB2012_data.xlsx', index_col=None,\n",
    "                     names=['X1', 'X2', 'X3', 'X4', 'X5', \n",
    "                            'X6', 'X7', 'X8', 'HL', 'CL'])\n",
    "\n",
    "# Divide train and test\n",
    "np.random.seed(0)\n",
    "[train, test] = train_test_split(data, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.762182</td>\n",
       "      <td>673.430782</td>\n",
       "      <td>318.619707</td>\n",
       "      <td>177.405537</td>\n",
       "      <td>5.221498</td>\n",
       "      <td>3.485342</td>\n",
       "      <td>0.236401</td>\n",
       "      <td>2.806189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.105228</td>\n",
       "      <td>88.027282</td>\n",
       "      <td>43.099064</td>\n",
       "      <td>45.030589</td>\n",
       "      <td>1.751195</td>\n",
       "      <td>1.108596</td>\n",
       "      <td>0.132973</td>\n",
       "      <td>1.544308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.620000</td>\n",
       "      <td>514.500000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>110.250000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.660000</td>\n",
       "      <td>594.125000</td>\n",
       "      <td>294.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.740000</td>\n",
       "      <td>686.000000</td>\n",
       "      <td>318.500000</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>759.500000</td>\n",
       "      <td>343.000000</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>808.500000</td>\n",
       "      <td>416.500000</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X1          X2          X3          X4          X5          X6  \\\n",
       "count  614.000000  614.000000  614.000000  614.000000  614.000000  614.000000   \n",
       "mean     0.762182  673.430782  318.619707  177.405537    5.221498    3.485342   \n",
       "std      0.105228   88.027282   43.099064   45.030589    1.751195    1.108596   \n",
       "min      0.620000  514.500000  245.000000  110.250000    3.500000    2.000000   \n",
       "25%      0.660000  594.125000  294.000000  147.000000    3.500000    3.000000   \n",
       "50%      0.740000  686.000000  318.500000  220.500000    3.500000    3.000000   \n",
       "75%      0.850000  759.500000  343.000000  220.500000    7.000000    4.000000   \n",
       "max      0.980000  808.500000  416.500000  220.500000    7.000000    5.000000   \n",
       "\n",
       "               X7          X8  \n",
       "count  614.000000  614.000000  \n",
       "mean     0.236401    2.806189  \n",
       "std      0.132973    1.544308  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.100000    1.250000  \n",
       "50%      0.250000    3.000000  \n",
       "75%      0.400000    4.000000  \n",
       "max      0.400000    5.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train.iloc[:, 0:8]\n",
    "X_test = test.iloc[:, 0:8]\n",
    "Y_train = train.iloc[:, 8:10]\n",
    "Y_test = test.iloc[:, 8:10]\n",
    "\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setting and optimizing the model\n",
    "\n",
    "You will train two independent GPs, one to estimate HL and one to estimate CL. For each of the two GPs ...\n",
    "\n",
    "**On the training data set:**\n",
    "\n",
    "a) Build a GP regression model based on a RBF kernel with ARD, in which each input dimension is weighted with a different lengthscale. **1.5 points**\n",
    "\n",
    "b) Fit the covariance function parameters and noise variance. **1 point** \n",
    "\n",
    "c) According to the ARD parameters found, what variables are more important for the regression? Compare it to Table 8 in this [paper](https://www.sciencedirect.com/science/article/pii/S037877881200151X) **1.5 points**\n",
    "\n",
    "**On the test data set:**\n",
    "\n",
    "d) Compute the test mean absolute error error and the test mean square error (MSE)  using the GP posterior mean and the optimized hyperparameters. Compare your results with Tables 6 and 7 in this [paper](https://www.sciencedirect.com/science/article/pii/S037877881200151X).\n",
    "**1.5 points**\n",
    "\n",
    "2) Try to improve your results by using a more complicated kernel, in which you combine various covariance functions. In this [link](http://nbviewer.jupyter.org/github/SheffieldML/notebook/blob/master/GPy/basic_kernels.ipynb) you can see how to define different kernels and combine  them. Comments the results. **2 points**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\toni3\\Anaconda3\\lib\\site-packages\\GPy\\kern\\src\\stationary.py:137: RuntimeWarning:overflow encountered in square\n",
      " C:\\Users\\toni3\\Anaconda3\\lib\\site-packages\\GPy\\kern\\src\\stationary.py:138: RuntimeWarning:invalid value encountered in add\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization restart 1/10, f = 572.3330239565826\n",
      "Optimization restart 2/10, f = 573.6398036951928\n",
      "Optimization restart 3/10, f = 569.9344714242858\n",
      "Optimization restart 4/10, f = 652.7763860608262\n",
      "Optimization restart 5/10, f = 574.3261273522012\n",
      "Optimization restart 6/10, f = 653.8032200777299\n",
      "Optimization restart 7/10, f = 645.0457515777847\n",
      "Optimization restart 8/10, f = 641.785543716634\n",
      "Optimization restart 9/10, f = 569.9344406504919\n",
      "Optimization restart 10/10, f = 569.934533717338\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".pd{\n",
       "    font-family: \"Courier New\", Courier, monospace !important;\n",
       "    width: 100%;\n",
       "    padding: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<p class=pd>\n",
       "<b>Model</b>: GP regression<br>\n",
       "<b>Objective</b>: 569.9344406504919<br>\n",
       "<b>Number of Parameters</b>: 10<br>\n",
       "<b>Number of Optimization Parameters</b>: 10<br>\n",
       "<b>Updates</b>: True<br>\n",
       "</p>\n",
       "<style type=\"text/css\">\n",
       ".tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\"><tr><th><b>  GP_regression.         </b></th><th><b>             value</b></th><th><b>constraints</b></th><th><b>priors</b></th></tr>\n",
       "<tr><td class=tg-left>  rbf.variance           </td><td class=tg-right> 410.0110198576648</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  rbf.lengthscale        </td><td class=tg-right>              (8,)</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  Gaussian_noise.variance</td><td class=tg-right>0.1827419549501253</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<GPy.models.gp_regression.GPRegression at 0x2a17444c6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".tg  {padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\">\n",
       "\n",
       "<tr>\n",
       "  <th><b>index</b></th>\n",
       "  <th><b>GP_regression.rbf.lengthscale</b></th>\n",
       "  <th><b>constraints</b></th><th><b>priors</b></th>\n",
       "</tr>\n",
       "<tr><td class=tg-left>  [0]  </td><td class=tg-right>                   0.75971677</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [1]  </td><td class=tg-right>                   1.41704057</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [2]  </td><td class=tg-right>                   0.25532836</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [3]  </td><td class=tg-right>                   0.91441782</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [4]  </td><td class=tg-right>                   0.40825187</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [5]  </td><td class=tg-right>                 946.25038242</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [6]  </td><td class=tg-right>                   0.25319274</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [7]  </td><td class=tg-right>                 164.97778373</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>"
      ],
      "text/plain": [
       "\u001b[1mGP_regression.rbf.lengthscale\u001b[0;0m:\n",
       "Param([7.59716770e-01, 1.41704057e+00, 2.55328358e-01, 9.14417823e-01,\n",
       "       4.08251868e-01, 9.46250382e+02, 2.53192743e-01, 1.64977784e+02])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".tg  {padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\">\n",
       "\n",
       "<tr>\n",
       "  <th><b>index</b></th>\n",
       "  <th><b>GP_regression.rbf.variance</b></th>\n",
       "  <th><b>constraints</b></th><th><b>priors</b></th>\n",
       "</tr>\n",
       "<tr><td class=tg-left>  [0]  </td><td class=tg-right>              410.01101986</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>"
      ],
      "text/plain": [
       "\u001b[1mGP_regression.rbf.variance\u001b[0;0m:\n",
       "Param([410.01101986])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# a) define Kernel\n",
    "ker_hl = GPy.kern.RBF(8,ARD=True) \n",
    "    # with the RBF-ARD each dimension has a different lengthscale\n",
    "\n",
    "# Create model\n",
    "m_hl = GPy.models.GPRegression(X_train.values,\n",
    "                               Y_train.HL.values.reshape([-1,1]),\n",
    "                               ker_hl)\n",
    "\n",
    "# b) Optimize model (fit parameters)\n",
    "m_hl.optimize_restarts(num_restarts = 10)\n",
    "display(m_hl)\n",
    "\n",
    "# c) Print final kernel parameters\n",
    "display(m_hl.kern.lengthscale)\n",
    "\n",
    "display(m_hl.kern.variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) According to the lengthscale values, the most important variable to predict HL are variables 3 and 7, because their lengthvalues are much smaller than that of the other dimensions. And the least important ones are the number 6 and 8. This more or less coincides with what the authors are showing in Table 8. For them, the most important feature is the 7th, and 6 and 8 are not that relevant (despite not the least relevant). The partial coincidence between both results is explained because the authors are using a completely different approach to check for feature importance: they are using the out-of-bag error of Random Forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization restart 1/10, f = 1250.1657867263978\n",
      "Optimization restart 2/10, f = 1250.1658407466416\n",
      "Optimization restart 3/10, f = 1250.1657023861503\n",
      "Optimization restart 4/10, f = 1250.1656952308533\n",
      "Optimization restart 5/10, f = 1250.1657522575936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\toni3\\Anaconda3\\lib\\site-packages\\GPy\\kern\\src\\stationary.py:166: RuntimeWarning:overflow encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization restart 6/10, f = 1272.6486656770053\n",
      "Optimization restart 7/10, f = 1250.1658188293409\n",
      "Optimization restart 8/10, f = 1281.339052732439\n",
      "Optimization restart 9/10, f = 1250.16569502004\n",
      "Optimization restart 10/10, f = 1250.1657005380166\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".pd{\n",
       "    font-family: \"Courier New\", Courier, monospace !important;\n",
       "    width: 100%;\n",
       "    padding: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<p class=pd>\n",
       "<b>Model</b>: GP regression<br>\n",
       "<b>Objective</b>: 1250.16569502004<br>\n",
       "<b>Number of Parameters</b>: 10<br>\n",
       "<b>Number of Optimization Parameters</b>: 10<br>\n",
       "<b>Updates</b>: True<br>\n",
       "</p>\n",
       "<style type=\"text/css\">\n",
       ".tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\"><tr><th><b>  GP_regression.         </b></th><th><b>            value</b></th><th><b>constraints</b></th><th><b>priors</b></th></tr>\n",
       "<tr><td class=tg-left>  rbf.variance           </td><td class=tg-right>541.8352464902207</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  rbf.lengthscale        </td><td class=tg-right>             (8,)</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  Gaussian_noise.variance</td><td class=tg-right>2.598928171107595</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<GPy.models.gp_regression.GPRegression at 0x2a17444c160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".tg  {padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\">\n",
       "\n",
       "<tr>\n",
       "  <th><b>index</b></th>\n",
       "  <th><b>GP_regression.rbf.lengthscale</b></th>\n",
       "  <th><b>constraints</b></th><th><b>priors</b></th>\n",
       "</tr>\n",
       "<tr><td class=tg-left>  [0]  </td><td class=tg-right>                   0.75971677</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [1]  </td><td class=tg-right>                   1.41704057</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [2]  </td><td class=tg-right>                   0.25532836</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [3]  </td><td class=tg-right>                   0.91441782</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [4]  </td><td class=tg-right>                   0.40825187</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [5]  </td><td class=tg-right>               65424.36139330</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [6]  </td><td class=tg-right>                   1.29961145</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [7]  </td><td class=tg-right>              145947.42185398</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>"
      ],
      "text/plain": [
       "\u001b[1mGP_regression.rbf.lengthscale\u001b[0;0m:\n",
       "Param([7.59716770e-01, 1.41704057e+00, 2.55328358e-01, 9.14417823e-01,\n",
       "       4.08251868e-01, 6.54243614e+04, 1.29961145e+00, 1.45947422e+05])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".tg  {padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\">\n",
       "\n",
       "<tr>\n",
       "  <th><b>index</b></th>\n",
       "  <th><b>GP_regression.rbf.variance</b></th>\n",
       "  <th><b>constraints</b></th><th><b>priors</b></th>\n",
       "</tr>\n",
       "<tr><td class=tg-left>  [0]  </td><td class=tg-right>              541.83524649</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>"
      ],
      "text/plain": [
       "\u001b[1mGP_regression.rbf.variance\u001b[0;0m:\n",
       "Param([541.83524649])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## CL OUTPUT VARIABLE\n",
    "np.random.seed(0)\n",
    "\n",
    "# define Kernel\n",
    "ker_cl = GPy.kern.RBF(8,ARD=True) \n",
    "    # with the RBF-ARD each dimension has a different lengthscale\n",
    "\n",
    "# Create model\n",
    "m_cl = GPy.models.GPRegression(X_train.values,\n",
    "                               Y_train.CL.values.reshape([-1,1]),\n",
    "                               ker_cl)\n",
    "\n",
    "# Optimize model (fit parameters)\n",
    "m_cl.optimize_restarts(num_restarts = 10)\n",
    "display(m_cl)\n",
    "\n",
    "# c) Print final kernel parameters\n",
    "display(m_cl.kern.lengthscale)\n",
    "\n",
    "display(m_cl.kern.variance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, variables 6 and 8 are considered the least important ones, in this case for predicting CL. And variables 3 and 5 are the most important ones. This does not coincide with the results of the paper, but the approaches used to compute these importances are completely different and meant for different algorithms, so this discrepancy is expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d) compute posterior means\n",
    "meanYtest_hl,_ = m_hl.predict(X_test.values)\n",
    "\n",
    "meanYtest_cl,_ = m_cl.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE HL:  0.352\n",
      "MSE HL:  0.263\n",
      "MAE CL:  1.237\n",
      "MSE CL:  3.424\n"
     ]
    }
   ],
   "source": [
    "# d) test mean absolute error and the test mean square error (MSE) \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "print('MAE HL: ', \n",
    "      round(mean_absolute_error(Y_test.HL.values,\n",
    "                                meanYtest_hl), 3))\n",
    "print('MSE HL: ', \n",
    "      round(mean_squared_error(Y_test.HL.values,\n",
    "                               meanYtest_hl), 3))\n",
    "\n",
    "print('MAE CL: ', \n",
    "      round(mean_absolute_error(Y_test.CL.values,\n",
    "                                meanYtest_cl), 3))\n",
    "print('MSE CL: ', \n",
    "      round(mean_squared_error(Y_test.CL.values,\n",
    "                               meanYtest_cl), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both output variables (HL and CL), Gaussian Processes outperforms Random Forest and classical linear regression algorithms used in the paper when we compare the Mean Square Errors. Mean Absolute Errors are not comparable since the authors of the paper do not show this metric in the tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\toni3\\Anaconda3\\lib\\site-packages\\GPy\\kern\\src\\stationary.py:166: RuntimeWarning:overflow encountered in true_divide\n",
      " C:\\Users\\toni3\\Anaconda3\\lib\\site-packages\\GPy\\kern\\src\\stationary.py:138: RuntimeWarning:invalid value encountered in add\n",
      " C:\\Users\\toni3\\Anaconda3\\lib\\site-packages\\GPy\\kern\\src\\stationary.py:168: RuntimeWarning:overflow encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization restart 1/10, f = 500.668275912545\n",
      "Optimization restart 2/10, f = 454.60145400690243\n",
      "Optimization restart 3/10, f = 611.5501042507506\n",
      "Optimization restart 4/10, f = 470.425608616558\n",
      "Optimization restart 5/10, f = 475.5085013300605\n",
      "Optimization restart 6/10, f = 522.0199995708565\n",
      "Optimization restart 7/10, f = 534.9740259442242\n",
      "Optimization restart 8/10, f = 472.5171230735865\n",
      "Optimization restart 9/10, f = 454.59904426168174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\toni3\\Anaconda3\\lib\\site-packages\\GPy\\kern\\src\\stationary.py:137: RuntimeWarning:overflow encountered in square\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization restart 10/10, f = 477.9328678643347\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".pd{\n",
       "    font-family: \"Courier New\", Courier, monospace !important;\n",
       "    width: 100%;\n",
       "    padding: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<p class=pd>\n",
       "<b>Model</b>: GP regression<br>\n",
       "<b>Objective</b>: 454.59904426168174<br>\n",
       "<b>Number of Parameters</b>: 12<br>\n",
       "<b>Number of Optimization Parameters</b>: 12<br>\n",
       "<b>Updates</b>: True<br>\n",
       "</p>\n",
       "<style type=\"text/css\">\n",
       ".tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\"><tr><th><b>  GP_regression.             </b></th><th><b>               value</b></th><th><b>constraints</b></th><th><b>priors</b></th></tr>\n",
       "<tr><td class=tg-left>  sum.rbf.variance           </td><td class=tg-right>  31.244103708271588</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  sum.rbf.lengthscale        </td><td class=tg-right>                (8,)</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  sum.Exponential.variance   </td><td class=tg-right>   508.6230609265717</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  sum.Exponential.lengthscale</td><td class=tg-right>  3463.1199899943003</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  Gaussian_noise.variance    </td><td class=tg-right>0.030003808344634928</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<GPy.models.gp_regression.GPRegression at 0x2a1744de588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE HL sum:  0.245\n",
      "MSE HL sum:  0.171\n",
      "\n",
      "\n",
      "MULTIPLICATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\toni3\\Anaconda3\\lib\\site-packages\\GPy\\kern\\src\\stationary.py:244: RuntimeWarning:invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization restart 1/10, f = 662.0289538282566\n",
      "Optimization restart 2/10, f = 588.511713863367\n",
      "Optimization restart 3/10, f = 546.1605034373417\n",
      "Optimization restart 4/10, f = 622.4060588209463\n",
      "Optimization restart 5/10, f = 711.6013993639591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\toni3\\Anaconda3\\lib\\site-packages\\GPy\\kern\\src\\stationary.py:137: RuntimeWarning:overflow encountered in square\n",
      " C:\\Users\\toni3\\Anaconda3\\lib\\site-packages\\GPy\\kern\\src\\stationary.py:138: RuntimeWarning:invalid value encountered in add\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization restart 6/10, f = 652.7686956190098\n",
      "Optimization restart 7/10, f = 1071.3637394840282\n",
      "Optimization restart 8/10, f = 687.8860977835641\n",
      "Optimization restart 9/10, f = 720.4792471112705\n",
      "Optimization restart 10/10, f = 506.06944309895925\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".pd{\n",
       "    font-family: \"Courier New\", Courier, monospace !important;\n",
       "    width: 100%;\n",
       "    padding: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<p class=pd>\n",
       "<b>Model</b>: GP regression<br>\n",
       "<b>Objective</b>: 506.06944309895925<br>\n",
       "<b>Number of Parameters</b>: 12<br>\n",
       "<b>Number of Optimization Parameters</b>: 12<br>\n",
       "<b>Updates</b>: True<br>\n",
       "</p>\n",
       "<style type=\"text/css\">\n",
       ".tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\"><tr><th><b>  GP_regression.             </b></th><th><b>                 value</b></th><th><b>constraints</b></th><th><b>priors</b></th></tr>\n",
       "<tr><td class=tg-left>  mul.rbf.variance           </td><td class=tg-right>     19.11062282225854</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  mul.rbf.lengthscale        </td><td class=tg-right>                  (8,)</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  mul.Exponential.variance   </td><td class=tg-right>    19.873222060342627</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  mul.Exponential.lengthscale</td><td class=tg-right>     1989.230883943509</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  Gaussian_noise.variance    </td><td class=tg-right>1.325235179585687e-133</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<GPy.models.gp_regression.GPRegression at 0x2a174507208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE HL product:  0.259\n",
      "MSE HL product:  0.17\n"
     ]
    }
   ],
   "source": [
    "# d) Try to improve your results by using a more complicated kernel, \n",
    "# in which you combine various covariance functions\n",
    "\n",
    "ker1 = GPy.kern.RBF(8,ARD=True)\n",
    "\n",
    "ker2 = GPy.kern.Exponential(8)\n",
    "\n",
    "ker_sum = ker1 + ker2 \n",
    "\n",
    "ker_prod = ker1*ker2\n",
    "\n",
    "print('SUM')\n",
    "# Create model\n",
    "m_sum = GPy.models.GPRegression(X_train.values,\n",
    "                                Y_train.HL.values.reshape([-1,1]),\n",
    "                                ker_sum)\n",
    "\n",
    "# b) Optimize model (fit parameters)\n",
    "m_sum.optimize_restarts(num_restarts = 10)\n",
    "display(m_sum)\n",
    "\n",
    "# d) compute posterior means\n",
    "meanYtest_sum,_ = m_sum.predict(X_test.values)\n",
    "\n",
    "print('MAE HL sum: ', \n",
    "      round(mean_absolute_error(Y_test.HL.values,\n",
    "                                meanYtest_sum), 3))\n",
    "print('MSE HL sum: ', \n",
    "      round(mean_squared_error(Y_test.HL.values,\n",
    "                               meanYtest_sum), 3))\n",
    "\n",
    "print('\\n')\n",
    "print('MULTIPLICATION')\n",
    "# Create model\n",
    "m_prod = GPy.models.GPRegression(X_train.values,\n",
    "                                 Y_train.HL.values.reshape([-1,1]),\n",
    "                                 ker_prod)\n",
    "\n",
    "# b) Optimize model (fit parameters)\n",
    "m_prod.optimize_restarts(num_restarts = 10)\n",
    "display(m_prod)\n",
    "\n",
    "# d) compute posterior means\n",
    "meanYtest_prod,_ = m_prod.predict(X_test.values)\n",
    "\n",
    "print('MAE HL product: ', \n",
    "      round(mean_absolute_error(Y_test.HL.values,\n",
    "                                meanYtest_prod), 3))\n",
    "print('MSE HL product: ', \n",
    "      round(mean_squared_error(Y_test.HL.values,\n",
    "                               meanYtest_prod), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example a combination of the previously used kernel with an exponential one is tested. Adding both kernels the errors decrease and multiplying them they decrease in a similar proportion.  \n",
    "\n",
    "In the next code chunk combinations in different dimensions will be tested. The rationale behind is to use the RBF kernel in the dimensions where it was seen that the lengthscale decreased significantly its value (they are important), and try other kernels in the other dimensions, whose lengthscale increased a lot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAT32\n",
      "Optimization restart 1/10, f = 606.1925011464764\n",
      "Optimization restart 2/10, f = 606.1925282830938\n",
      "Optimization restart 3/10, f = 606.1924062257805\n",
      "Optimization restart 4/10, f = 606.1925022696244\n",
      "Optimization restart 5/10, f = 606.1925145781022\n",
      "Optimization restart 6/10, f = 606.1923834322415\n",
      "Optimization restart 7/10, f = 670.015883944926\n",
      "Optimization restart 8/10, f = 670.0158659712528\n",
      "Optimization restart 9/10, f = 606.192257570419\n",
      "Optimization restart 10/10, f = 606.1925087129301\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".pd{\n",
       "    font-family: \"Courier New\", Courier, monospace !important;\n",
       "    width: 100%;\n",
       "    padding: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<p class=pd>\n",
       "<b>Model</b>: GP regression<br>\n",
       "<b>Objective</b>: 606.192257570419<br>\n",
       "<b>Number of Parameters</b>: 10<br>\n",
       "<b>Number of Optimization Parameters</b>: 10<br>\n",
       "<b>Updates</b>: True<br>\n",
       "</p>\n",
       "<style type=\"text/css\">\n",
       ".tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\"><tr><th><b>  GP_regression.         </b></th><th><b>             value</b></th><th><b>constraints</b></th><th><b>priors</b></th></tr>\n",
       "<tr><td class=tg-left>  mul.Mat32.variance     </td><td class=tg-right>21.850121969291596</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  mul.Mat32.lengthscale  </td><td class=tg-right>29.981036926003902</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  mul.rbf.variance       </td><td class=tg-right>21.782117693018733</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  mul.rbf.lengthscale    </td><td class=tg-right>              (6,)</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  Gaussian_noise.variance</td><td class=tg-right>0.0704824146148651</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<GPy.models.gp_regression.GPRegression at 0x2a1743a2d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE HL combination:  0.309\n",
      "MSE HL combination:  0.231\n"
     ]
    }
   ],
   "source": [
    "print('MAT32')\n",
    "k1 = GPy.kern.Matern32(input_dim=2, active_dims=[5, 7])\n",
    "k2 = GPy.kern.RBF(input_dim=6, \n",
    "                  active_dims=[0, 1, 2, 3, 4, 6],ARD=True)\n",
    "k_prod_dim = k1*k2\n",
    "\n",
    "# Create model\n",
    "m_prod_dim = GPy.models.GPRegression(X_train.values,\n",
    "                                     Y_train.HL.values.reshape([-1,1]),\n",
    "                                     k_prod_dim)\n",
    "\n",
    "# b) Optimize model (fit parameters)\n",
    "m_prod_dim.optimize_restarts(num_restarts = 10)\n",
    "display(m_prod_dim)\n",
    "\n",
    "# d) compute posterior means\n",
    "meanYtest_prod_dim,_ = m_prod_dim.predict(X_test.values)\n",
    "\n",
    "print('MAE HL combination: ', \n",
    "      round(mean_absolute_error(Y_test.HL.values,\n",
    "                                meanYtest_prod_dim), 3))\n",
    "print('MSE HL combination: ', \n",
    "      round(mean_squared_error(Y_test.HL.values,\n",
    "                               meanYtest_prod_dim), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the errors are slightly better, but not that much. It makes sense since the dimensions that RBF considered important are treated with an RBF kernel, and the others are treated with a Matern32 kernel, whose shape is somehow similar to that of RBF. This reinforces the idea that these two dimensions are not that relevant for these types of classifiers (in the paper it was shown thay they do have some importance for RF). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear\n",
      "Optimization restart 1/10, f = 2088.984040735274\n",
      "Optimization restart 2/10, f = 2088.9840407358865\n",
      "Optimization restart 3/10, f = 2088.984040471972\n",
      "Optimization restart 4/10, f = 2088.9840407294455\n",
      "Optimization restart 5/10, f = 2088.984040207557\n",
      "Optimization restart 6/10, f = 2088.984040736335\n",
      "Optimization restart 7/10, f = 2088.9840407615347\n",
      "Optimization restart 8/10, f = 2088.9840407691518\n",
      "Optimization restart 9/10, f = 2088.9840406779344\n",
      "Optimization restart 10/10, f = 2088.984040734516\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".pd{\n",
       "    font-family: \"Courier New\", Courier, monospace !important;\n",
       "    width: 100%;\n",
       "    padding: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<p class=pd>\n",
       "<b>Model</b>: GP regression<br>\n",
       "<b>Objective</b>: 2088.984040207557<br>\n",
       "<b>Number of Parameters</b>: 9<br>\n",
       "<b>Number of Optimization Parameters</b>: 9<br>\n",
       "<b>Updates</b>: True<br>\n",
       "</p>\n",
       "<style type=\"text/css\">\n",
       ".tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\"><tr><th><b>  GP_regression.         </b></th><th><b>             value</b></th><th><b>constraints</b></th><th><b>priors</b></th></tr>\n",
       "<tr><td class=tg-left>  mul.linear.variances   </td><td class=tg-right>3.7430762824609016</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  mul.rbf.variance       </td><td class=tg-right> 3.650696551471754</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  mul.rbf.lengthscale    </td><td class=tg-right>              (6,)</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  Gaussian_noise.variance</td><td class=tg-right> 42.80287065039799</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<GPy.models.gp_regression.GPRegression at 0x2a1744ad390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE HL combination:  5.349\n",
      "MSE HL combination:  47.707\n"
     ]
    }
   ],
   "source": [
    "print('Linear')\n",
    "k1 = GPy.kern.Linear(input_dim=2, active_dims=[5, 7])\n",
    "k2 = GPy.kern.RBF(input_dim=6,\n",
    "                  active_dims=[0, 1, 2, 3, 4, 6],ARD=True)\n",
    "k_prod_dim = k1*k2\n",
    "\n",
    "# Create model\n",
    "m_prod_dim = GPy.models.GPRegression(X_train.values,\n",
    "                                     Y_train.HL.values.reshape([-1,1]),\n",
    "                                     k_prod_dim)\n",
    "\n",
    "# b) Optimize model (fit parameters)\n",
    "m_prod_dim.optimize_restarts(num_restarts = 10)\n",
    "display(m_prod_dim)\n",
    "\n",
    "# d) compute posterior means\n",
    "meanYtest_prod_dim,_ = m_prod_dim.predict(X_test.values)\n",
    "\n",
    "print('MAE HL combination: ', \n",
    "      round(mean_absolute_error(Y_test.HL.values,\n",
    "                                meanYtest_prod_dim), 3))\n",
    "print('MSE HL combination: ', \n",
    "      round(mean_squared_error(Y_test.HL.values,\n",
    "                               meanYtest_prod_dim), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear kernel is clearly a bad choice. Despite most dimensions are treated with an RBF, the errors have increased a lot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExpQuad\n",
      "Optimization restart 1/10, f = 574.3119956570767\n",
      "Optimization restart 2/10, f = 687.318970313743\n",
      "Optimization restart 3/10, f = 787.3281652090664\n",
      "Optimization restart 4/10, f = 574.3119975888445\n",
      "Optimization restart 5/10, f = 574.3119532159296\n",
      "Optimization restart 6/10, f = 574.3119129636947\n",
      "Optimization restart 7/10, f = 1955.336243617529\n",
      "Optimization restart 8/10, f = 574.3119834094935\n",
      "Optimization restart 9/10, f = 787.3281656666314\n",
      "Optimization restart 10/10, f = 574.312011119073\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".pd{\n",
       "    font-family: \"Courier New\", Courier, monospace !important;\n",
       "    width: 100%;\n",
       "    padding: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<p class=pd>\n",
       "<b>Model</b>: GP regression<br>\n",
       "<b>Objective</b>: 574.3119129636947<br>\n",
       "<b>Number of Parameters</b>: 10<br>\n",
       "<b>Number of Optimization Parameters</b>: 10<br>\n",
       "<b>Updates</b>: True<br>\n",
       "</p>\n",
       "<style type=\"text/css\">\n",
       ".tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\"><tr><th><b>  GP_regression.         </b></th><th><b>              value</b></th><th><b>constraints</b></th><th><b>priors</b></th></tr>\n",
       "<tr><td class=tg-left>  mul.ExpQuad.variance   </td><td class=tg-right> 18.389071206617004</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  mul.ExpQuad.lengthscale</td><td class=tg-right> 248.34468322323815</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  mul.rbf.variance       </td><td class=tg-right>  23.32604469767295</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  mul.rbf.lengthscale    </td><td class=tg-right>               (6,)</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  Gaussian_noise.variance</td><td class=tg-right>0.18465505738903928</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<GPy.models.gp_regression.GPRegression at 0x2a174479128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE HL combination:  0.354\n",
      "MSE HL combination:  0.268\n"
     ]
    }
   ],
   "source": [
    "print('ExpQuad')\n",
    "k1 = GPy.kern.ExpQuad(input_dim=2, active_dims=[5, 7])\n",
    "k2 = GPy.kern.RBF(input_dim=6, \n",
    "                  active_dims=[0, 1, 2, 3, 4, 6],ARD=True)\n",
    "k_prod_dim = k1*k2\n",
    "\n",
    "# Create model\n",
    "m_prod_dim = GPy.models.GPRegression(X_train.values,\n",
    "                                     Y_train.HL.values.reshape([-1,1]),\n",
    "                                     k_prod_dim)\n",
    "\n",
    "# b) Optimize model (fit parameters)\n",
    "m_prod_dim.optimize_restarts(num_restarts = 10)\n",
    "display(m_prod_dim)\n",
    "\n",
    "# d) compute posterior means\n",
    "meanYtest_prod_dim,_ = m_prod_dim.predict(X_test.values)\n",
    "\n",
    "print('MAE HL combination: ', \n",
    "      round(mean_absolute_error(Y_test.HL.values,\n",
    "                                meanYtest_prod_dim), 3))\n",
    "print('MSE HL combination: ', \n",
    "      round(mean_squared_error(Y_test.HL.values,\n",
    "                               meanYtest_prod_dim), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Errors are now similar to those obtained with the original RBF-ARD kernel. \n",
    "\n",
    "In the next chunk the same combinations are applied for the second output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAT32\n",
      "Optimization restart 1/10, f = 1003.9336988177629\n",
      "Optimization restart 2/10, f = 1003.9338532449358\n",
      "Optimization restart 3/10, f = 1003.9336018817958\n",
      "Optimization restart 4/10, f = 1003.9337306164729\n",
      "Optimization restart 5/10, f = 1003.9337257154534\n",
      "Optimization restart 6/10, f = 1003.9335627902042\n",
      "Optimization restart 7/10, f = 1003.9336477317304\n",
      "Optimization restart 8/10, f = 1003.9336872605334\n",
      "Optimization restart 9/10, f = 1003.9337183808972\n",
      "Optimization restart 10/10, f = 1003.9325797243937\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".pd{\n",
       "    font-family: \"Courier New\", Courier, monospace !important;\n",
       "    width: 100%;\n",
       "    padding: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<p class=pd>\n",
       "<b>Model</b>: GP regression<br>\n",
       "<b>Objective</b>: 1003.9325797243937<br>\n",
       "<b>Number of Parameters</b>: 10<br>\n",
       "<b>Number of Optimization Parameters</b>: 10<br>\n",
       "<b>Updates</b>: True<br>\n",
       "</p>\n",
       "<style type=\"text/css\">\n",
       ".tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\"><tr><th><b>  GP_regression.         </b></th><th><b>              value</b></th><th><b>constraints</b></th><th><b>priors</b></th></tr>\n",
       "<tr><td class=tg-left>  mul.Mat32.variance     </td><td class=tg-right> 21.830987983883862</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  mul.Mat32.lengthscale  </td><td class=tg-right>  8.148211854199362</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  mul.rbf.variance       </td><td class=tg-right> 24.198716995894035</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  mul.rbf.lengthscale    </td><td class=tg-right>               (6,)</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  Gaussian_noise.variance</td><td class=tg-right>0.15542244161580446</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<GPy.models.gp_regression.GPRegression at 0x2a102578ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE CL combination:  0.364\n",
      "MSE CL combination:  0.234\n",
      "Linear\n",
      "Optimization restart 1/10, f = 2133.15999099935\n",
      "Optimization restart 2/10, f = 2133.159990774875\n",
      "Optimization restart 3/10, f = 2133.1599912053266\n",
      "Optimization restart 4/10, f = 2133.159991002891\n",
      "Optimization restart 5/10, f = 2133.1599898811787\n",
      "Optimization restart 6/10, f = 2133.1599910409027\n",
      "Optimization restart 7/10, f = 2133.1599910026725\n",
      "Optimization restart 8/10, f = 2133.1599909743954\n",
      "Optimization restart 9/10, f = 2133.159991042265\n",
      "Optimization restart 10/10, f = 2133.1599910277855\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".pd{\n",
       "    font-family: \"Courier New\", Courier, monospace !important;\n",
       "    width: 100%;\n",
       "    padding: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<p class=pd>\n",
       "<b>Model</b>: GP regression<br>\n",
       "<b>Objective</b>: 2133.1599898811787<br>\n",
       "<b>Number of Parameters</b>: 9<br>\n",
       "<b>Number of Optimization Parameters</b>: 9<br>\n",
       "<b>Updates</b>: True<br>\n",
       "</p>\n",
       "<style type=\"text/css\">\n",
       ".tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\"><tr><th><b>  GP_regression.         </b></th><th><b>             value</b></th><th><b>constraints</b></th><th><b>priors</b></th></tr>\n",
       "<tr><td class=tg-left>  mul.linear.variances   </td><td class=tg-right> 4.034700361987271</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  mul.rbf.variance       </td><td class=tg-right> 4.038284005555551</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  mul.rbf.lengthscale    </td><td class=tg-right>              (6,)</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  Gaussian_noise.variance</td><td class=tg-right>50.319526064468505</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<GPy.models.gp_regression.GPRegression at 0x2a1744bc2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE CL combination:  5.855\n",
      "MSE CL combination:  57.715\n",
      "ExpQuad\n",
      "Optimization restart 1/10, f = 1228.897966655857\n",
      "Optimization restart 2/10, f = 1250.1659182652668\n",
      "Optimization restart 3/10, f = 1228.8979658345584\n",
      "Optimization restart 4/10, f = 1228.8979720694665\n",
      "Optimization restart 5/10, f = 1228.8979594023936\n",
      "Optimization restart 6/10, f = 1228.8979093116927\n",
      "Optimization restart 7/10, f = 1228.898001367446\n",
      "Optimization restart 8/10, f = 1250.1658448346175\n",
      "Optimization restart 9/10, f = 1250.1658507398402\n",
      "Optimization restart 10/10, f = 1250.1659316442547\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".pd{\n",
       "    font-family: \"Courier New\", Courier, monospace !important;\n",
       "    width: 100%;\n",
       "    padding: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<p class=pd>\n",
       "<b>Model</b>: GP regression<br>\n",
       "<b>Objective</b>: 1228.8979093116927<br>\n",
       "<b>Number of Parameters</b>: 10<br>\n",
       "<b>Number of Optimization Parameters</b>: 10<br>\n",
       "<b>Updates</b>: True<br>\n",
       "</p>\n",
       "<style type=\"text/css\">\n",
       ".tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\"><tr><th><b>  GP_regression.         </b></th><th><b>              value</b></th><th><b>constraints</b></th><th><b>priors</b></th></tr>\n",
       "<tr><td class=tg-left>  mul.ExpQuad.variance   </td><td class=tg-right> 16.704848990797316</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  mul.ExpQuad.lengthscale</td><td class=tg-right>  1.732180390171366</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  mul.rbf.variance       </td><td class=tg-right>  18.77491798439703</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  mul.rbf.lengthscale    </td><td class=tg-right>               (6,)</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  Gaussian_noise.variance</td><td class=tg-right>0.19317933458155764</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<GPy.models.gp_regression.GPRegression at 0x2a102562080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE CL combination:  0.496\n",
      "MSE CL combination:  0.452\n"
     ]
    }
   ],
   "source": [
    "print('MAT32')\n",
    "k1 = GPy.kern.Matern32(input_dim=2, active_dims=[5, 7])\n",
    "k2 = GPy.kern.RBF(input_dim=6, \n",
    "                  active_dims=[0, 1, 2, 3, 4, 6],ARD=True)\n",
    "k_prod_dim = k1*k2\n",
    "\n",
    "# Create model\n",
    "m_prod_dim = GPy.models.GPRegression(X_train.values,\n",
    "                                     Y_train.CL.values.reshape([-1,1]),\n",
    "                                     k_prod_dim)\n",
    "\n",
    "# b) Optimize model (fit parameters)\n",
    "m_prod_dim.optimize_restarts(num_restarts = 10)\n",
    "display(m_prod_dim)\n",
    "\n",
    "# d) compute posterior means\n",
    "meanYtest_prod_dim,_ = m_prod_dim.predict(X_test.values)\n",
    "\n",
    "print('MAE CL combination: ', \n",
    "      round(mean_absolute_error(Y_test.CL.values,\n",
    "                                meanYtest_prod_dim), 3))\n",
    "print('MSE CL combination: ', \n",
    "      round(mean_squared_error(Y_test.CL.values,\n",
    "                               meanYtest_prod_dim), 3))\n",
    "\n",
    "print('Linear')\n",
    "k1 = GPy.kern.Linear(input_dim=2, active_dims=[5, 7])\n",
    "k2 = GPy.kern.RBF(input_dim=6,\n",
    "                  active_dims=[0, 1, 2, 3, 4, 6],ARD=True)\n",
    "k_prod_dim = k1*k2\n",
    "\n",
    "# Create model\n",
    "m_prod_dim = GPy.models.GPRegression(X_train.values,\n",
    "                                     Y_train.CL.values.reshape([-1,1]),\n",
    "                                     k_prod_dim)\n",
    "\n",
    "# b) Optimize model (fit parameters)\n",
    "m_prod_dim.optimize_restarts(num_restarts = 10)\n",
    "display(m_prod_dim)\n",
    "\n",
    "# d) compute posterior means\n",
    "meanYtest_prod_dim,_ = m_prod_dim.predict(X_test.values)\n",
    "\n",
    "print('MAE CL combination: ', \n",
    "      round(mean_absolute_error(Y_test.CL.values,\n",
    "                                meanYtest_prod_dim), 3))\n",
    "print('MSE CL combination: ', \n",
    "      round(mean_squared_error(Y_test.CL.values,\n",
    "                               meanYtest_prod_dim), 3))\n",
    "\n",
    "print('ExpQuad')\n",
    "k1 = GPy.kern.ExpQuad(input_dim=2, active_dims=[5, 7])\n",
    "k2 = GPy.kern.RBF(input_dim=6, \n",
    "                  active_dims=[0, 1, 2, 3, 4, 6],ARD=True)\n",
    "k_prod_dim = k1*k2\n",
    "\n",
    "# Create model\n",
    "m_prod_dim = GPy.models.GPRegression(X_train.values,\n",
    "                                     Y_train.CL.values.reshape([-1,1]),\n",
    "                                     k_prod_dim)\n",
    "\n",
    "# b) Optimize model (fit parameters)\n",
    "m_prod_dim.optimize_restarts(num_restarts = 10)\n",
    "display(m_prod_dim)\n",
    "\n",
    "# d) compute posterior means\n",
    "meanYtest_prod_dim,_ = m_prod_dim.predict(X_test.values)\n",
    "\n",
    "print('MAE CL combination: ', \n",
    "      round(mean_absolute_error(Y_test.CL.values,\n",
    "                                meanYtest_prod_dim), 3))\n",
    "print('MSE CL combination: ', \n",
    "      round(mean_squared_error(Y_test.CL.values,\n",
    "                               meanYtest_prod_dim), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, combining the RBF kernel with either a Mat32 or with an Exponential Quadratic improves the models! The two least important dimensions for RBF were not considered at all, and these two other kernels take advantage of them and obtain valuable information to improve the predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse GP implementation \n",
    "\n",
    "Try to implement an sparse version of the GP regressor, optimized to find a set of **inducing points** that the GP relies on to do the prediction. Measure the test error prediction for 20, 40, and 100 inducing points. **2.5 points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inducing points:  20\n",
      "Optimization restart 1/10, f = 2493.0722722749388\n",
      "Optimization restart 2/10, f = 2830.619746160595\n",
      "Optimization restart 3/10, f = 2830.6197485253247\n",
      "Optimization restart 4/10, f = 2830.6197461310344\n",
      "Optimization restart 5/10, f = 2830.6197479186603\n",
      "Optimization restart 6/10, f = 2830.619746138678\n",
      "Optimization restart 7/10, f = 2830.6197492694478\n",
      "Optimization restart 8/10, f = 2830.619750231142\n",
      "Optimization restart 9/10, f = 2830.6197507693405\n",
      "Optimization restart 10/10, f = 2830.6197461995193\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".pd{\n",
       "    font-family: \"Courier New\", Courier, monospace !important;\n",
       "    width: 100%;\n",
       "    padding: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<p class=pd>\n",
       "<b>Model</b>: sparse_gp<br>\n",
       "<b>Objective</b>: 2493.0722722749388<br>\n",
       "<b>Number of Parameters</b>: 170<br>\n",
       "<b>Number of Optimization Parameters</b>: 170<br>\n",
       "<b>Updates</b>: True<br>\n",
       "</p>\n",
       "<style type=\"text/css\">\n",
       ".tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\"><tr><th><b>  sparse_gp.             </b></th><th><b>            value</b></th><th><b>constraints</b></th><th><b>priors</b></th></tr>\n",
       "<tr><td class=tg-left>  inducing inputs        </td><td class=tg-right>          (20, 8)</td><td class=tg-center>           </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  rbf.variance           </td><td class=tg-right> 69.6574223211995</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  rbf.lengthscale        </td><td class=tg-right>             (8,)</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  Gaussian_noise.variance</td><td class=tg-right>170.6760323469479</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<GPy.models.sparse_gp_regression.SparseGPRegression at 0x2a1025621d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE HL Sparse:  8.806\n",
      "MSE HL Sparse:  218.659\n",
      "\n",
      "\n",
      "Number of inducing points:  40\n",
      "Optimization restart 1/10, f = 1360.9656246845698\n",
      "Optimization restart 2/10, f = 2830.61974867374\n",
      "Optimization restart 3/10, f = 2830.6197487018826\n",
      "Optimization restart 4/10, f = 2830.619748526581\n",
      "Optimization restart 5/10, f = 2830.619746127673\n",
      "Optimization restart 6/10, f = 2830.6197481835\n",
      "Optimization restart 7/10, f = 2830.6197486805518\n",
      "Optimization restart 8/10, f = 2830.619749361234\n",
      "Optimization restart 9/10, f = 2830.6197494362805\n",
      "Optimization restart 10/10, f = 2830.619746086794\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".pd{\n",
       "    font-family: \"Courier New\", Courier, monospace !important;\n",
       "    width: 100%;\n",
       "    padding: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<p class=pd>\n",
       "<b>Model</b>: sparse_gp<br>\n",
       "<b>Objective</b>: 1360.9656246845698<br>\n",
       "<b>Number of Parameters</b>: 330<br>\n",
       "<b>Number of Optimization Parameters</b>: 330<br>\n",
       "<b>Updates</b>: True<br>\n",
       "</p>\n",
       "<style type=\"text/css\">\n",
       ".tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\"><tr><th><b>  sparse_gp.             </b></th><th><b>             value</b></th><th><b>constraints</b></th><th><b>priors</b></th></tr>\n",
       "<tr><td class=tg-left>  inducing inputs        </td><td class=tg-right>           (40, 8)</td><td class=tg-center>           </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  rbf.variance           </td><td class=tg-right>28.856458208809915</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  rbf.lengthscale        </td><td class=tg-right>              (8,)</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  Gaussian_noise.variance</td><td class=tg-right> 2.618279910055161</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<GPy.models.sparse_gp_regression.SparseGPRegression at 0x2a1744709b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE HL Sparse:  0.996\n",
      "MSE HL Sparse:  1.836\n",
      "\n",
      "\n",
      "Number of inducing points:  100\n",
      "Optimization restart 1/10, f = 850.1540155223338\n",
      "Optimization restart 2/10, f = 2830.6197490336144\n",
      "Optimization restart 3/10, f = 2830.6197481789313\n",
      "Optimization restart 4/10, f = 2830.619748697845\n",
      "Optimization restart 5/10, f = 2830.619748296242\n",
      "Optimization restart 6/10, f = 2830.6197490783743\n",
      "Optimization restart 7/10, f = 2830.6197490220093\n",
      "Optimization restart 8/10, f = 2830.619750004184\n",
      "Optimization restart 9/10, f = 2830.6197461086535\n",
      "Optimization restart 10/10, f = 2830.6197461776037\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".pd{\n",
       "    font-family: \"Courier New\", Courier, monospace !important;\n",
       "    width: 100%;\n",
       "    padding: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<p class=pd>\n",
       "<b>Model</b>: sparse_gp<br>\n",
       "<b>Objective</b>: 850.1540155223338<br>\n",
       "<b>Number of Parameters</b>: 810<br>\n",
       "<b>Number of Optimization Parameters</b>: 810<br>\n",
       "<b>Updates</b>: True<br>\n",
       "</p>\n",
       "<style type=\"text/css\">\n",
       ".tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\"><tr><th><b>  sparse_gp.             </b></th><th><b>             value</b></th><th><b>constraints</b></th><th><b>priors</b></th></tr>\n",
       "<tr><td class=tg-left>  inducing inputs        </td><td class=tg-right>          (100, 8)</td><td class=tg-center>           </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  rbf.variance           </td><td class=tg-right> 216.8269118826798</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  rbf.lengthscale        </td><td class=tg-right>              (8,)</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  Gaussian_noise.variance</td><td class=tg-right>0.4371464804679775</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<GPy.models.sparse_gp_regression.SparseGPRegression at 0x2a174507d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE HL Sparse:  0.512\n",
      "MSE HL Sparse:  0.513\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "ind_points = [20, 40, 100]\n",
    "np.random.seed(0)\n",
    "\n",
    "for i in range(0,3):\n",
    "    \n",
    "    ker = GPy.kern.RBF(8,ARD=True)\n",
    "    \n",
    "    print('Number of inducing points: ', ind_points[i])\n",
    "    \n",
    "    # define model\n",
    "    m = GPy.models.SparseGPRegression(X_train.values,\n",
    "                                      Y_train.HL.values.reshape([-1,1]),\n",
    "                                      ker,\n",
    "                                      num_inducing=ind_points[i])\n",
    "    \n",
    "    # optimize model\n",
    "    m.optimize_restarts(num_restarts = 10)\n",
    "    display(m)\n",
    "    \n",
    "    # prediction\n",
    "    meanYtest,_ = m.predict(X_test.values)\n",
    "    print('MAE HL Sparse: ', \n",
    "          round(mean_absolute_error(Y_test.HL.values,\n",
    "                                    meanYtest), 3))\n",
    "    print('MSE HL Sparse: ', \n",
    "          round(mean_squared_error(Y_test.HL.values,\n",
    "                                   meanYtest), 3))\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    del ker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the number of inducing points keeps increasing, the value of the objective function and that of the error also decrease, which is benefitious because, reducing the computational cost, a model with a similar quality to that of the full input X matrix is obtained. \n",
    "\n",
    "In the next code chunk the same experiment is performed but for the other output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inducing points:  20\n",
      "Optimization restart 1/10, f = 2532.145563995802\n",
      "Optimization restart 2/10, f = 2878.25041500431\n",
      "Optimization restart 3/10, f = 2878.2504097801257\n",
      "Optimization restart 4/10, f = 2878.250414515378\n",
      "Optimization restart 5/10, f = 2878.2504138796967\n",
      "Optimization restart 6/10, f = 2878.2504145996145\n",
      "Optimization restart 7/10, f = 2878.2504100121932\n",
      "Optimization restart 8/10, f = 2878.250409854932\n",
      "Optimization restart 9/10, f = 2878.2504100204997\n",
      "Optimization restart 10/10, f = 2878.250412086638\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".pd{\n",
       "    font-family: \"Courier New\", Courier, monospace !important;\n",
       "    width: 100%;\n",
       "    padding: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<p class=pd>\n",
       "<b>Model</b>: sparse_gp<br>\n",
       "<b>Objective</b>: 2532.145563995802<br>\n",
       "<b>Number of Parameters</b>: 170<br>\n",
       "<b>Number of Optimization Parameters</b>: 170<br>\n",
       "<b>Updates</b>: True<br>\n",
       "</p>\n",
       "<style type=\"text/css\">\n",
       ".tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\"><tr><th><b>  sparse_gp.             </b></th><th><b>             value</b></th><th><b>constraints</b></th><th><b>priors</b></th></tr>\n",
       "<tr><td class=tg-left>  inducing inputs        </td><td class=tg-right>           (20, 8)</td><td class=tg-center>           </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  rbf.variance           </td><td class=tg-right> 80.66546872747345</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  rbf.lengthscale        </td><td class=tg-right>              (8,)</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  Gaussian_noise.variance</td><td class=tg-right>193.38246604336453</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<GPy.models.sparse_gp_regression.SparseGPRegression at 0x2a17450e160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE CL Sparse:  8.798\n",
      "MSE CL Sparse:  230.962\n",
      "\n",
      "\n",
      "Number of inducing points:  40\n",
      "Optimization restart 1/10, f = 1423.344706840675\n",
      "Optimization restart 2/10, f = 2878.250409839213\n",
      "Optimization restart 3/10, f = 2878.250415176998\n",
      "Optimization restart 4/10, f = 2878.2504097646183\n",
      "Optimization restart 5/10, f = 2878.2504121548923\n",
      "Optimization restart 6/10, f = 2878.2504146343013\n",
      "Optimization restart 7/10, f = 2878.2504140527553\n",
      "Optimization restart 8/10, f = 2878.2504100437686\n",
      "Optimization restart 9/10, f = 2878.250410001598\n",
      "Optimization restart 10/10, f = 2878.2504147448885\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".pd{\n",
       "    font-family: \"Courier New\", Courier, monospace !important;\n",
       "    width: 100%;\n",
       "    padding: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<p class=pd>\n",
       "<b>Model</b>: sparse_gp<br>\n",
       "<b>Objective</b>: 1423.344706840675<br>\n",
       "<b>Number of Parameters</b>: 330<br>\n",
       "<b>Number of Optimization Parameters</b>: 330<br>\n",
       "<b>Updates</b>: True<br>\n",
       "</p>\n",
       "<style type=\"text/css\">\n",
       ".tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\"><tr><th><b>  sparse_gp.             </b></th><th><b>            value</b></th><th><b>constraints</b></th><th><b>priors</b></th></tr>\n",
       "<tr><td class=tg-left>  inducing inputs        </td><td class=tg-right>          (40, 8)</td><td class=tg-center>           </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  rbf.variance           </td><td class=tg-right>662.5576352066741</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  rbf.lengthscale        </td><td class=tg-right>             (8,)</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  Gaussian_noise.variance</td><td class=tg-right>4.683443797554055</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<GPy.models.sparse_gp_regression.SparseGPRegression at 0x2a17450ea90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE CL Sparse:  1.756\n",
      "MSE CL Sparse:  5.98\n",
      "\n",
      "\n",
      "Number of inducing points:  100\n",
      "Optimization restart 1/10, f = 1252.2915101789404\n",
      "Optimization restart 2/10, f = 2878.2504100515903\n",
      "Optimization restart 3/10, f = 2878.2504143259293\n",
      "Optimization restart 4/10, f = 2878.2504148061316\n",
      "Optimization restart 5/10, f = 2878.2504149301417\n",
      "Optimization restart 6/10, f = 2878.250409975251\n",
      "Optimization restart 7/10, f = 2878.250410046659\n",
      "Optimization restart 8/10, f = 2878.2504101490886\n",
      "Optimization restart 9/10, f = 2878.2504124901116\n",
      "Optimization restart 10/10, f = 2878.250411564509\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".pd{\n",
       "    font-family: \"Courier New\", Courier, monospace !important;\n",
       "    width: 100%;\n",
       "    padding: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<p class=pd>\n",
       "<b>Model</b>: sparse_gp<br>\n",
       "<b>Objective</b>: 1252.2915101789404<br>\n",
       "<b>Number of Parameters</b>: 810<br>\n",
       "<b>Number of Optimization Parameters</b>: 810<br>\n",
       "<b>Updates</b>: True<br>\n",
       "</p>\n",
       "<style type=\"text/css\">\n",
       ".tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\"><tr><th><b>  sparse_gp.             </b></th><th><b>            value</b></th><th><b>constraints</b></th><th><b>priors</b></th></tr>\n",
       "<tr><td class=tg-left>  inducing inputs        </td><td class=tg-right>         (100, 8)</td><td class=tg-center>           </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  rbf.variance           </td><td class=tg-right>812.4147525791623</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  rbf.lengthscale        </td><td class=tg-right>             (8,)</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  Gaussian_noise.variance</td><td class=tg-right>2.614538945288757</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<GPy.models.sparse_gp_regression.SparseGPRegression at 0x2a17450eb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE CL Sparse:  1.24\n",
      "MSE CL Sparse:  3.448\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ind_points = [20, 40, 100]\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "for i in range(0,3):\n",
    "    \n",
    "    ker = GPy.kern.RBF(8,ARD=True)\n",
    "    \n",
    "    print('Number of inducing points: ', ind_points[i])\n",
    "    \n",
    "    # define model\n",
    "    m = GPy.models.SparseGPRegression(X_train.values,\n",
    "                                      Y_train.CL.values.reshape([-1,1]),\n",
    "                                      ker,\n",
    "                                      num_inducing=ind_points[i])\n",
    "    \n",
    "    # optimize model\n",
    "    m.optimize_restarts(num_restarts = 10)\n",
    "    display(m)\n",
    "    \n",
    "    # prediction\n",
    "    meanYtest,_ = m.predict(X_test.values)\n",
    "    print('MAE CL Sparse: ', \n",
    "          round(mean_absolute_error(Y_test.CL.values,\n",
    "                                    meanYtest), 3))\n",
    "    print('MSE CL Sparse: ', \n",
    "          round(mean_squared_error(Y_test.CL.values,\n",
    "                                   meanYtest), 3))\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    del ker"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
